{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYzF8XCsmHfR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# downloading stopwords corpus\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "nltk.download('conll2000')\n",
        "nltk.download('brown')\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/Amazon_Reviews_Oneplus_10R.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "7p2j56-DpVSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df.copy()\n",
        "df2=df.copy()\n",
        "df3=df.head()"
      ],
      "metadata": {
        "id": "9dzwbk0gpb2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[\"char_count\"]=df[\"Review\"].str.len()\n",
        "df1[[\"Review\",\"char_count\"]].head()"
      ],
      "metadata": {
        "id": "DuTyn3c4QkhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2[\"word_count\"]=df[\"Review\"].apply(lambda x:len(str(x).split(\" \")))\n",
        "df2[[\"Review\",\"word_count\"]].head()"
      ],
      "metadata": {
        "id": "Sj8T6cieQkd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop=stopwords.words(\"english\")\n",
        "df3[\"stopwords\"]=df3[\"Review\"].apply(lambda x:len([x for x in x.split() if x in stop]))\n",
        "df3[[\"Review\",\"stopwords\"]]"
      ],
      "metadata": {
        "id": "HI89DZq1Qkb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['Unnamed: 0','Rating','Title',\"Review_Date\"])"
      ],
      "metadata": {
        "id": "vEcCLFxxS3-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Text Preprocessing\n",
        "#PreProcessing\n",
        "df['Final_review'] = df['Review'].str.replace(r'@\\w+', '')\n",
        "\n",
        "# Display the modified DataFrame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "kNy3Z1m_SL_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing reviews with empty text\n",
        "df = df[df['Final_review']!='']\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "PAtog-QWSzpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_reviews = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    # Check if the entry is a string\n",
        "    if isinstance(row.Final_review, str):\n",
        "        # Filtering out words that contain links\n",
        "        words_without_links = [word for word in row.Final_review.split() if 'http' not in word]\n",
        "        cleaned_reviews.append(' '.join(words_without_links))\n",
        "    else:\n",
        "        # Handle non-string entries (e.g., if the entry is a float)\n",
        "        cleaned_reviews.append('')\n",
        "\n",
        "# Create a new column with cleaned reviews\n",
        "df['Final_review'] = cleaned_reviews\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "9ZD3l-uOU-aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting text to lowercase, removing text in square brackets,removing links, punctuation and  words containing numbers\n",
        "def clean_text(text):\n",
        "\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text\n",
        "\n",
        "df['Final_review']=df['Final_review'].apply(lambda x: clean_text(x))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "MdE_V7HtTnju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing Emojis\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\" u\"\\U0001F600-\\U0001F64F\" u\"\\U0001F300-\\U0001F5FF\"u\"\\U0001F680-\\U0001F6FF\" u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "df['Final_review']=df['Final_review'].apply(lambda x: remove_emoji(x))\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "F3tXAnB-VlCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokenized_review'] = df['Final_review'].apply(lambda x: nltk.word_tokenize(x))\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "yQDdV-fdVt9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['Final_review'])"
      ],
      "metadata": {
        "id": "HWg-AedJV7_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stopwords\n",
        "from nltk.corpus import stopwords\n",
        "my_stop_words=stopwords.words('english')\n",
        "sw = ['am','using','phone','may']\n",
        "my_stop_words.extend(sw)\n",
        "stopwords_set = set(my_stop_words)\n",
        "cleaned_tweets = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "\n",
        "    # filerting out all the stopwords\n",
        "     words_without_stopwords = [word for word in row.tokenized_review if word.lower() not in my_stop_words and '#' not in word.lower()]\n",
        "\n",
        "    # finally creating tweets list of tuples containing stopwords(list) and sentimentType\n",
        "     cleaned_tweets.append(' '.join(words_without_stopwords))\n",
        "\n",
        "df['Final_review'] = cleaned_tweets\n",
        "df.head()"
      ],
      "metadata": {
        "id": "SBawyxw0WA7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatization\n",
        "tokenized_review = df['Final_review'].apply(lambda x: x.split())\n",
        "word_lemmatizer = WordNetLemmatizer()\n",
        "tokenized_review = tokenized_review.apply(lambda x: [word_lemmatizer.lemmatize(i) for i in x])"
      ],
      "metadata": {
        "id": "ZA21ZhmtWVNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Final_review'] = tokenized_review\n",
        "df['Final_review'] = df['Final_review'].apply(lambda x: ' '.join(x))\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "pdtif-fpXDzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Extraction\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "def fetch_sentiment_using_SIA(text):\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "    polarity_scores = sid.polarity_scores(text)\n",
        "    return 'neg' if polarity_scores['neg'] > polarity_scores['pos'] else 'pos'\n",
        "\n",
        "sentiments_using_SIA = df.Final_review.apply(lambda x: fetch_sentiment_using_SIA(x))\n",
        "pd.DataFrame(sentiments_using_SIA.value_counts())"
      ],
      "metadata": {
        "id": "7czLw52mXDuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4=pd.DataFrame()\n",
        "df4['Reviews'] = df.Final_review\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "df4['scores'] = df4['Reviews'].apply(lambda x: sid.polarity_scores(x))\n",
        "df4['compound']  = df4['scores'].apply(lambda x: x['compound'])\n",
        "df4 = df4.drop(columns=['scores'])\n",
        "df4.head()\n"
      ],
      "metadata": {
        "id": "BruMreN0XwvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4['sentiment'] = df4['compound'].apply(lambda c: 'Positive' if c >= 0.05 else 'Negative' if c <= -0.05 else 'Neutral')\n",
        "df4.head()"
      ],
      "metadata": {
        "id": "kACzEEXAYFOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4['sentiment'].value_counts()"
      ],
      "metadata": {
        "id": "y2ImjEYvYIdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(df4['sentiment'])"
      ],
      "metadata": {
        "id": "i5YsP4DUYLIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "allWords_ = ' '.join([review for review in df['Final_review']])\n",
        "f, axes = plt.subplots(figsize=(10,8))\n",
        "wordcloud= WordCloud(\n",
        "        background_color = 'black',\n",
        "        width = 1800,\n",
        "        height =1400).generate(allWords_)\n",
        "plt.imshow(wordcloud)"
      ],
      "metadata": {
        "id": "HcCRM_vtYNDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wr2GUjPDYkXr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}